{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSMC 불러와서 정제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 감정분석을 위해, Naver Movie Corpus(https://github.com/e9t/nsmc/) 를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(filename):\n",
    "    # NSMC 불러오는 함수.\n",
    "\n",
    "    return documents\n",
    "    \n",
    "train_docs = read_documents(\"data/nsmc/ratings_train.txt\")\n",
    "test_docs = read_documents(\"data/nsmc/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_docs))\n",
    "print(len(test_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(doc):\n",
    "    # 한국어를 제외한 글자를 제거하는 함수.\n",
    "    doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)\n",
    "    return doc\n",
    "\n",
    "def define_stopwords(path):\n",
    "    \n",
    "    SW = set()\n",
    "    # 불용어를 추가하는 방법 1.\n",
    "    # SW.add(\"있다\")\n",
    "    \n",
    "    # 불용어를 추가하는 방법 2.\n",
    "    # stopwords-ko.txt에 직접 추가\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "            \n",
    "    return SW\n",
    "\n",
    "def text_tokenizing(doc):\n",
    "    return [word for word in mecab.morphs(doc) if word not in SW and len(word) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불러온 데이터를 품사 태그를 붙여서 토크나이징합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# 형태소 분석기 불러오기\n",
    "okt = Okt()\n",
    "mecab = Mecab()\n",
    "\n",
    "SW = define_stopwords(\"data/stopwords-ko.txt\")\n",
    "\n",
    "# 텍스트가 20만개이기 때문에, 정제하는데 시간이 걸린다.\n",
    "# 한 번 만들고 나서는 코드를 다시 실행시켰을 때, 또 정제할 필요없이 불러오게끔 코드를 짜보자.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK를 이용한 histogram 분석."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 분석을 하기 위해 기본적인 정보들을 확인합니다.\n",
    "\n",
    "* nltk 라이브러리를 이용하여 전처리를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "total_tokens = [token for doc in train_data for token in doc[0]]\n",
    "print(len(total_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(total_tokens, name='NMSC')\n",
    "print(len(set(text.tokens)))\n",
    "pprint(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram 그리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~')\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "text.plot(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud 그리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud 라이브러리를 설치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "data = text.vocab().most_common(50)\n",
    "\n",
    "# for windows : font_path='c:/Windows/Fonts/malgun.ttf'\n",
    "wordcloud = WordCloud(font_path='/Library/Fonts/AppleGothic.ttf',\n",
    "                      relative_scaling = 0.2,\n",
    "                      #stopwords=STOPWORDS,\n",
    "                      background_color='white',\n",
    "                      ).generate_from_frequencies(dict(data))\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
