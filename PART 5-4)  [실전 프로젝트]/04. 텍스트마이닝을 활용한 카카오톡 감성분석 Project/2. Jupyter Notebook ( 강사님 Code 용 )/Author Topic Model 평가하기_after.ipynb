{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import AuthorTopicModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim import corpora\n",
    "from tqdm import tqdm_notebook\n",
    "from pprint import pprint\n",
    "\n",
    "# 사용자간의 유사성을 평가하기 위한 measure를 사용하기 위해 불러오기\n",
    "from gensim.matutils import hellinger\n",
    "from gensim import matutils\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 4\n",
    "\n",
    "if not os.path.exists(\"kakao(ATM)_model\"):\n",
    "    model = AuthorTopicModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary.id2token, \\\n",
    "                author2doc=author2doc, passes=10)\n",
    "    model.save('kakao(ATM)_model')\n",
    "else:\n",
    "    model = AuthorTopicModel.load(\"kakao(ATM)_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('닥쳐', 0.00913352474795045),\n",
       " ('오우', 0.006077150842656581),\n",
       " ('핡', 0.005814291204809277),\n",
       " ('넌', 0.004275330190804228),\n",
       " ('그게', 0.003936329056179983),\n",
       " ('찍', 0.003518902685383488),\n",
       " ('됨', 0.0033362068393125244),\n",
       " ('일단', 0.0031497496609154147),\n",
       " ('가서', 0.0030418551056656984),\n",
       " ('올', 0.002905564005796451)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토픽별 분포 확인하기\n",
    "model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 라벨 지정.\n",
    "topic_labels = [\"Topic0\", \"Topic1\", \"Topic2\", \"Topic3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Topic0\n",
      "Words: 닥쳐 오우 핡 넌 그게 찍 됨 일단 가서 올 뭐야 야 집 이게 신촌 둘다 기모찌 팬더 도착 이건 \n",
      "\n",
      "Label: Topic1\n",
      "Words: 나는 다 이제 그냥 당연 역시 뭐 같이 이미 가능 좋음 왜 진짜 튜브 그래도 솬 곧 존나 있음 프로도신 \n",
      "\n",
      "Label: Topic2\n",
      "Words: 예아 괜찮 갑자기 이꾸 하앙 둘이 보면 있는데 뭐임마 컴 미친 같음 개꿀 연구실 밥임 그러게 항상 치킨 솔직히 아닌데 \n",
      "\n",
      "Label: Topic3\n",
      "Words: 굿 아 난 프로도 근데 핳 허허 오늘 나도 내가 나 오 라이언 그럼 굳 프로도이 지금 어피치 핳핳 좀 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토픽별로 topN 단어 확인하기.\n",
    "for topic in model.show_topics(NUM_TOPICS):\n",
    "    print('Label: ' + topic_labels[topic[0]])\n",
    "    words = ''\n",
    "    for word, prob in model.show_topic(topic[0], topn=20):\n",
    "        words += word + ' '\n",
    "    print('Words: ' + words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자별로 토픽 분포 확인하기.\n",
    "def show_author(name):\n",
    "    print('\\n%s' % name)\n",
    "    print('Docs:', model.author2doc[name])\n",
    "    print('Topics:')\n",
    "    pprint([(topic_labels[topic[0]], topic[1]) for topic in model[name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "네오\n",
      "Docs: [273, 274, 276, 277, 342, 374, 396, 3799, 3800, 3802, 3806, 3808, 3814, 3816, 3818, 3820, 3823, 3824, 3826, 3828, 3831, 3834, 3835, 3838, 3841, 3863, 3864, 3865, 3866, 3870, 3872, 3877, 3885, 3888, 3889, 3904, 3905, 3907, 3912, 3916, 3920, 3926, 3944, 3949, 3951, 3952, 3953, 3958, 3962, 4433, 4434, 4442, 4444, 4451, 4452, 4453, 4455, 4459, 4460, 4466, 4467, 4469, 4473, 4476, 4477, 4479, 4487, 4489, 4495, 4497, 4499, 4505, 4506, 4508, 4510, 4513, 4515, 4516, 4517, 4519, 4521, 4523, 4527, 4530, 4533, 4535, 4536, 4542, 4547, 4551, 4556, 4558, 15826, 32378, 32379, 32383, 32385, 32386, 32388, 32405, 32408, 32412, 32413, 32416, 32419, 42387, 42390, 42391, 42394, 42399, 42410, 42489, 42492, 42493, 42494, 42496, 45428, 45431, 45438, 45439, 45457, 45458, 48980, 48981, 48982, 48983, 48989, 49907, 49909, 49912, 49913, 49915, 49917, 49919, 49921, 49938, 49941, 49943, 49945, 49946, 49949, 84471, 84472, 84477, 84478, 84482, 84485, 84489, 84491, 85677, 93507, 93508, 93510, 93511, 107221, 107310, 107311, 107312, 107313, 107325, 107326, 107328, 107331, 107334, 107956, 107957, 107960, 107961, 107964, 107969, 107970, 107971, 107974, 108112, 128437, 128441, 128443, 128448, 128449, 128459, 128461, 128464, 128470, 128473, 128475, 128484, 128488, 128491, 128502, 128504, 128511, 128512, 128518, 128522, 128525, 128537, 128539, 128545, 128551, 128553, 128560, 128569, 128577, 128588, 128601, 128603, 128612, 128617, 128628, 128630, 128637, 128641, 128645, 128650, 128654, 128657, 128658, 128666, 128668, 128669, 128674, 128675, 128676, 128677, 128681, 128683, 128686, 128688, 128690, 128694, 128698, 128700, 128704, 128707, 128710, 128713, 128715, 128716, 128720, 128721, 128722, 128726, 128727, 128730, 128734, 128736, 128737, 128741, 128743, 128744, 128751, 128753, 128757, 128761, 128765, 128766, 128773, 128774, 128779, 128783, 128788, 128789, 128790, 128792, 128794, 128796, 128799, 128802, 128804, 128809, 128811, 128813, 128816, 128821, 128824, 128825, 128826, 128827, 128829, 128831, 128832, 128838, 128839, 136379, 136380, 136385, 136387, 136393, 137503, 146228, 146232, 146235, 146236, 146238, 146243, 146244, 146252, 146262, 146263, 146264, 146266, 146269, 146271, 146272, 146274, 154475, 154477, 154914, 154940, 158105, 158109, 158111, 158112, 158116, 158117, 158119, 158752, 158753, 158755, 161767, 161768, 161774, 161775, 161780]\n",
      "Topics:\n",
      "[('Topic0', 0.14798956342038022),\n",
      " ('Topic1', 0.30637663906281004),\n",
      " ('Topic2', 0.15846342670808514),\n",
      " ('Topic3', 0.38717037080872463)]\n"
     ]
    }
   ],
   "source": [
    "# \"네오\"의 토픽 분포 확인.\n",
    "show_author('네오')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.14798956342038022),\n",
       "  (1, 0.30637663906281004),\n",
       "  (2, 0.15846342670808514),\n",
       "  (3, 0.38717037080872463)],\n",
       " [(0, 0.0880999332585824),\n",
       "  (1, 0.493662980893337),\n",
       "  (2, 0.14462030211383983),\n",
       "  (3, 0.2736167837342408)],\n",
       " [(0, 0.13377666097787727),\n",
       "  (1, 0.21083885589015972),\n",
       "  (2, 0.0971719396849559),\n",
       "  (3, 0.5582125434470071)],\n",
       " [(0, 0.11025390157874199),\n",
       "  (1, 0.4469268384813222),\n",
       "  (2, 0.07415173994093803),\n",
       "  (3, 0.3686675199989978)],\n",
       " [(0, 0.04065800921486131),\n",
       "  (1, 0.20711683329874),\n",
       "  (2, 0.1468495200964532),\n",
       "  (3, 0.6053756373899456)],\n",
       " [(0, 0.3438993754743885),\n",
       "  (1, 0.25765725089249314),\n",
       "  (2, 0.11776001705181706),\n",
       "  (3, 0.2806833565813014)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.get_author_topics(author) for author in model.id2author.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hellinger Distance를 이용하여 비슷한 토픽을 가진 사용자를 추정하는 함수.\n",
    "\n",
    "\n",
    "# author-topic 분포 만들기\n",
    "author_vecs = [model.get_author_topics(author) for author in model.id2author.values()]\n",
    " \n",
    "def similarity(vec1, vec2):\n",
    "    # vec1, vec2 사이의 hellinger similarity 구하기.\n",
    "    dist = hellinger(matutils.sparse2full(vec1, model.num_topics), \\\n",
    "                              matutils.sparse2full(vec2, model.num_topics))\n",
    "    sim = 1.0 / (1.0 + dist)\n",
    "    return sim\n",
    " \n",
    "def get_sims(vec):\n",
    "    # 각 사용자들 사이의 similarity pair 구하기.\n",
    "    sims = [similarity(vec, vec2) for vec2 in author_vecs]\n",
    "    return sims\n",
    " \n",
    "def get_table(name, top_n=10, smallest_author=1):\n",
    "    \"\"\"\n",
    "    주어진 사용자에 대해서 topN 사람만큼 유사도를 정렬해서 table을 출력하는 함수입니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 유사도 측정하기\n",
    "    sims = get_sims(model.get_author_topics(name))\n",
    " \n",
    "    # 저자별 정보 정렬하기\n",
    "    table = []\n",
    "    for elem in enumerate(sims):\n",
    "        author_name = model.id2author[elem[0]]\n",
    "        sim = elem[1]\n",
    "        author_size = len(model.author2doc[author_name])\n",
    "        if author_size >= smallest_author:\n",
    "            table.append((author_name, sim, author_size))\n",
    "            \n",
    "    # 사용자 패턴 분석 결과를 Dataframe으로 만들기\n",
    "    df = pd.DataFrame(table, columns=['Author', 'Score', 'Size'])\n",
    "    df = df.sort_values('Score', ascending=False)[:top_n]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Score</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>무지</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네오</td>\n",
       "      <td>0.887220</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>튜브</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>42358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어피치</td>\n",
       "      <td>0.846163</td>\n",
       "      <td>12741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>프로도</td>\n",
       "      <td>0.817804</td>\n",
       "      <td>20514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>라이언</td>\n",
       "      <td>0.803962</td>\n",
       "      <td>39311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author     Score   Size\n",
       "2     무지  1.000000  48320\n",
       "0     네오  0.887220    324\n",
       "4     튜브  0.886143  42358\n",
       "3    어피치  0.846163  12741\n",
       "5    프로도  0.817804  20514\n",
       "1    라이언  0.803962  39311"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자별 대화 패턴 검증\n",
    "get_table('무지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
